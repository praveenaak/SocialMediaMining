# -*- coding: utf-8 -*-
"""SMM_Proj_API_Tweet_Extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KCb62bSFDq4IsrfwN6ssCBHSr4-LptG2
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import itertools
import collections

import tweepy as tw
import nltk
from nltk import bigrams
from nltk.corpus import stopwords
import re
import networkx as nx

import warnings
warnings.filterwarnings("ignore")

consumer_key= 'lcEQDtVZGBA9Qdv6pcpZ68pUH'
consumer_secret= '1BoH0QrlTy3GaVHsZ5rkGYkrzLPeFQMkqSGdKdTHi0nh8LY7SA'
access_token= '1570576523136241664-2Eog7HcVjoxAu99IsRtBrTDlqX3q4t'
access_token_secret= 'dXo7tNdlJ71suUfyEjRpYOt0fKZjGnqhOTFizUS8CQj8L'

auth = tw.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
api = tw.API(auth, wait_on_rate_limit=True)

# Create a custom search term and define the number of tweets
search_term = "#VaccinesSaveLives OR #VaccinesWork OR #ImVaccinated -filter:retweets"

tweets = tw.Cursor(api.search,
                   q=search_term,
                   lang="en").items(5000)

import json
count = 0
json_data = []
for tweet in tweets:
  count+=1
  json_data.append(tweet._json)

print(count)

with open('ProVtweets3.json', 'w') as json_file:
    json.dump(json_data, json_file)